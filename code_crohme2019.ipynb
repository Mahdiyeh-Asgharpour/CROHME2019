{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gaqBabKgYEBz",
        "outputId": "26d400ff-0f18-4af0-e8d0-5582c554199c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/kaggle/input/crohme2019'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#download the dataset\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"ntcuong2103/crohme2019\")\n",
        "path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# authored by me for parsing and rendering InkML handwriting data\n",
        "\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display\n",
        "from glob import glob\n",
        "\n",
        "# parse an InkML file and optionally save the rendered trace image\n",
        "def parse_and_render_inkml(file_path, save_path=None):\n",
        "    \"\"\"\n",
        "    Parses an InkML (.inkml) file, extracts stroke data (traces),\n",
        "    renders it as a handwriting image using matplotlib,\n",
        "    and optionally saves the image to a file.\n",
        "    \"\"\"\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    traces = []\n",
        "    # extract all <trace> elements\n",
        "    for trace in root.findall(\".//{http://www.w3.org/2003/InkML}trace\"):\n",
        "        raw_points = trace.text.strip().split(',')\n",
        "        stroke = []\n",
        "        for point in raw_points:\n",
        "            coords = point.strip().split()\n",
        "            if len(coords) == 2:\n",
        "                stroke.append([float(coords[0]), float(coords[1])])\n",
        "        if stroke:\n",
        "            traces.append(np.array(stroke))\n",
        "\n",
        "    # create a figure and draw the strokes\n",
        "    fig, ax = plt.subplots()\n",
        "    for stroke in traces:\n",
        "        ax.plot(stroke[:, 0], -stroke[:, 1], linewidth=2)  # flip y-axis\n",
        "\n",
        "    ax.axis('off')\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "    # save the figure if path provided, otherwise show it\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "# explore folder contents and count files with optional extension\n",
        "def explore_directory(dir_path, extension=None):\n",
        "    print(f\"Exploring directory: {dir_path}\\n\")\n",
        "    if not os.path.exists(dir_path):\n",
        "        print(\"Path does not exist.\")\n",
        "        return\n",
        "\n",
        "    subdirs = [d for d in os.listdir(dir_path) if os.path.isdir(os.path.join(dir_path, d))]\n",
        "    files = [f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))]\n",
        "\n",
        "    print(f\"Subfolders: {len(subdirs)}\")\n",
        "    for d in subdirs:\n",
        "        print(\"  └──\", d)\n",
        "\n",
        "    if extension:\n",
        "        matching = [f for f in files if f.endswith(extension)]\n",
        "        print(f\"\\n .{extension} files: {len(matching)}\")\n",
        "    else:\n",
        "        print(f\"\\n Total files: {len(files)}\")\n",
        "\n",
        "# check contents of all relevant data folders\n",
        "explore_directory(\"/kaggle/input/crohme2019/crohme2019/crohme2019/test/\", \".inkml\")\n",
        "explore_directory(\"/kaggle/input/crohme2019/crohme2019/crohme2019/train/\", \".inkml\")\n",
        "explore_directory(\"/kaggle/input/crohme2019/crohme2019/crohme2019/valid/\", \".inkml\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYX3JffW1DOP",
        "outputId": "4d497809-1798-42f9-c86a-a07af7ef7f94"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exploring directory: /kaggle/input/crohme2019/crohme2019/crohme2019/test/\n",
            "\n",
            "Subfolders: 0\n",
            "\n",
            " ..inkml files: 1199\n",
            "Exploring directory: /kaggle/input/crohme2019/crohme2019/crohme2019/train/\n",
            "\n",
            "Subfolders: 0\n",
            "\n",
            " ..inkml files: 8901\n",
            "Exploring directory: /kaggle/input/crohme2019/crohme2019/crohme2019/valid/\n",
            "\n",
            "Subfolders: 0\n",
            "\n",
            " ..inkml files: 986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parsing label file and saving structured labels to CSV\n",
        "import pandas as pd\n",
        "\n",
        "# this is the path to the ground-truth label file\n",
        "label_file_path = \"/kaggle/input/crohme2019/crohme2019_train.txt\"\n",
        "\n",
        "# list to hold parsed (file_path, label_text) pairs\n",
        "label_entries = []\n",
        "\n",
        "# read each line from the label file and split into components\n",
        "with open(label_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if line:  # skip empty lines\n",
        "            parts = line.split(maxsplit=1)  # split into path and label\n",
        "            if len(parts) == 2:\n",
        "                label_entries.append(parts)\n",
        "\n",
        "# convert parsed data into a DataFrame\n",
        "df = pd.DataFrame(label_entries, columns=[\"file_path\", \"label\"])\n",
        "\n",
        "# extract just the file name from the path (for easier matching later)\n",
        "df[\"file_name\"] = df[\"file_path\"].apply(lambda x: x.split(\"/\")[-1])\n",
        "\n",
        "# tokenize label string into list of tokens\n",
        "df[\"tokens\"] = df[\"label\"].str.split()\n",
        "\n",
        "# export the DataFrame to a CSV file for later use\n",
        "df.to_csv(\"/kaggle/working/train_labels.csv\", index=False)\n",
        "print(\" Label data saved to train_labels.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ymkP804w5Gk",
        "outputId": "fd83f3c9-a78d-4c06-82c4-136cd41ede69"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label data saved to train_labels.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parsing label file and saving structured labels to CSV\n",
        "import pandas as pd\n",
        "\n",
        "# this is the path to the ground-truth label file for test set\n",
        "label_file_path = \"/content/crohme2019_test.txt\"\n",
        "\n",
        "# list to hold parsed (file_path, label_text) pairs\n",
        "label_entries = []\n",
        "\n",
        "# read each line from the label file and split into components\n",
        "with open(label_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if line:  # skip empty lines\n",
        "            parts = line.split(maxsplit=1)  # split into path and label\n",
        "            if len(parts) == 2:\n",
        "                label_entries.append(parts)\n",
        "\n",
        "# convert parsed data into a DataFrame\n",
        "df = pd.DataFrame(label_entries, columns=[\"file_path\", \"label\"])\n",
        "\n",
        "# extract just the file name from the path (for easier matching later)\n",
        "df[\"file_name\"] = df[\"file_path\"].apply(lambda x: x.split(\"/\")[-1])\n",
        "\n",
        "# tokenize label string into list of tokens\n",
        "df[\"tokens\"] = df[\"label\"].str.split()\n",
        "\n",
        "# export the DataFrame to a CSV file for later use\n",
        "df.to_csv(\"test_labels.csv\", index=False)\n",
        "print(\" Label data saved to test_labels.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTLWCa3kw5oI",
        "outputId": "a9827303-9208-4fd6-e0f7-c5c8fcda0163"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label data saved to test_labels.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parsing label file and saving structured labels to CSV\n",
        "import pandas as pd\n",
        "\n",
        "# this is the path to the ground-truth label file for validation set\n",
        "label_file_path = \"/content/crohme2019_valid.txt\"\n",
        "\n",
        "# list to hold parsed (file_path, label_text) pairs\n",
        "label_entries = []\n",
        "\n",
        "# read each line from the label file and split into components\n",
        "with open(label_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if line:  # skip empty lines\n",
        "            parts = line.split(maxsplit=1)  # split into path and label\n",
        "            if len(parts) == 2:\n",
        "                label_entries.append(parts)\n",
        "\n",
        "# convert parsed data into a DataFrame\n",
        "df = pd.DataFrame(label_entries, columns=[\"file_path\", \"label\"])\n",
        "\n",
        "# extract just the file name from the path (for easier matching later)\n",
        "df[\"file_name\"] = df[\"file_path\"].apply(lambda x: x.split(\"/\")[-1])\n",
        "\n",
        "# tokenize label string into list of tokens\n",
        "df[\"tokens\"] = df[\"label\"].str.split()\n",
        "\n",
        "# export the DataFrame to a CSV file for later use\n",
        "df.to_csv(\"valid_labels.csv\", index=False)\n",
        "print(\" Label data saved to valid_labels.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7AwLUVaxy_B",
        "outputId": "fe3d0cd7-6a1c-42dd-a21d-83733577b3ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label data saved to valid_labels.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}